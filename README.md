# TEXT PROCESSING 

  
  
 
# => Text Cleaning Class
In this module, an efficient text cleaning is implemented with various text cleaning features such as Noise reduction, Standardization, Elimination of Stop Words
Lemmatization, also referred to as stemming and this module can be directly imported and used for quick and efficientÂ cleaning
            
           
           
 # => Text Encoding Class
Instead of encoding text using the BERT vocabulary, this function encodes text for the BERT model and models based on custom vocabulary. When we wish to forecast tokens by utilising the softmax layer as the last layer, this can help reduce the amount of computational expense that is associated with NLP models. When compared to the BERT vocabulary, which contains around 30,000 terms, the use of bespoke vocabulary will result in a reduction in the overall size of the vocabulary.
           
            
      
 
