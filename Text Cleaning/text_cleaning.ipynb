{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyenchant\n",
        "import nltk\n",
        "nltk.download(\"words\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeZgNPP65Ubx",
        "outputId": "75546394-a03c-4c7d-b462-56f4a2c872fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyenchant in /usr/local/lib/python3.8/dist-packages (3.2.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import enchant\n",
        "import string\n",
        "import regex\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import words as eng_words\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "enhQFb945EZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextCleaning:\n",
        "   def __init__(self,stemming: bool):\n",
        "       self._ps = PorterStemmer()\n",
        "       if type(stemming) is not bool:\n",
        "        raise TypeError(\"Parameter < stemming > must be < bool >\")\n",
        "       else:\n",
        "        self._stem = stemming\n",
        "       self._eng = enchant.Dict(\"en_US\")\n",
        "       self._sw = self._imp_stop_words()\n",
        "       self._double = np.squeeze(pd.read_csv(\n",
        "           \"https://raw.githubusercontent.com/NITHISHM2410/Text_Processing/NLP/Text%20Cleaning/double_identical.txt\",\n",
        "           header=None).values).tolist()\n",
        "       self._notwords = np.squeeze(pd.read_csv(\"https://raw.githubusercontent.com/NITHISHM2410/Text_Processing/NLP/Text%20Cleaning/negative%20words.txt\",\n",
        "                                               header=None).values.tolist())\n",
        "       self._notwords = self.ready_not_words()\n",
        "       self._eng_words = self.ready_eng_words()\n",
        " \n",
        "   def ready_eng_words(self):\n",
        "       self._eng_words = eng_words.words()\n",
        "       self._eng_words += self._notwords\n",
        "       return self._eng_words\n",
        "\n",
        "   def ready_not_words(self):\n",
        "       self._notwords = [i.replace(\"'\", \"\") for i in self._notwords]\n",
        "       self._notwords.append(\"not\")\n",
        "       return self._notwords\n",
        "\n",
        "   @staticmethod\n",
        "   def _imp_stop_words():\n",
        "       words = stopwords.words(\"english\")\n",
        "       words.append(\"hello\")\n",
        "       ntwords = [i for i in words if \"n't\" in i or i[-1] == 'n']\n",
        "       ntwords.remove('between')\n",
        "       ntwords.remove('again')\n",
        "       ntwords.remove('on')\n",
        "       ntwords.remove('an')\n",
        "       ntwords.remove('won')\n",
        "       ntwords.remove('when')\n",
        "       ntwords.remove('than')\n",
        "       ntwords.remove('then')\n",
        "       ntwords = ntwords[5:]\n",
        "       stop_words = set(words) - set(ntwords)\n",
        "       stop_words.remove(\"not\")\n",
        "       return stop_words\n",
        "   def not_list(self):\n",
        "       return self._notwords\n",
        "\n",
        "   def _remove_consec_duplicates(self,s):\n",
        "       new_s = \"\"\n",
        "       prev = \"\"\n",
        "       for c in s:\n",
        "           if len(new_s) == 0:\n",
        "               new_s += c\n",
        "               prev = c\n",
        "           if c == prev:\n",
        "               continue\n",
        "           else:\n",
        "               new_s += c\n",
        "               prev = c\n",
        "       return new_s\n",
        "\n",
        "   def clean(self,series):\n",
        "       for i in range(len(series)):\n",
        "           series[i] = self._cleaner(series[i])\n",
        "       return series\n",
        "  \n",
        "   def _cleaner(self,sent):\n",
        "       cur = time.time()\n",
        "       sent = sent.split()\n",
        "       sent = [i.lower() for i in sent]\n",
        "       sent = [i for i in sent if i not in self._sw]\n",
        "       for i in sent:\n",
        "           if 'http' in i or 'html' in i or 'www' in i or '.com' in i:\n",
        "               sent.remove(i)\n",
        "       sent = \" \".join(sent)\n",
        "       sent = list(sent)\n",
        "       sent = [i for i in sent if not i.isdigit()]\n",
        "       sent = \"\".join(sent)\n",
        "       sent = sent.split()\n",
        "       sent = \" \".join(sent)\n",
        "       sent = list(sent)\n",
        "       sent = \"\".join([i for i in sent if i not in string.punctuation])  \n",
        "       sent = sent.split()\n",
        "       sent = [i for i in sent if not len(i) <= 2]\n",
        "       end = time.time()\n",
        "       print(\"Lower,Number removal,punc removal \",\"%.5f\" % end-cur)\n",
        "       cur = time.time()\n",
        "       for i in sent:\n",
        "           ind = sent.index(i)\n",
        "           if i in self._double:\n",
        "               continue\n",
        "           else:\n",
        "               i = self._remove_consec_duplicates(i)\n",
        "               sent[ind] = i              \n",
        "       for i in sent:\n",
        "           if i not in self._eng_words:\n",
        "               sent.remove(i)      \n",
        "       end = time.time()\n",
        "       print(\"http,double,conce \", \"%.5f\" % end-cur)              \n",
        "       if self._stem:\n",
        "           sent = [self._ps.stem(i) for i in sent]\n",
        "       sent = \" \".join(sent)\n",
        "   \n",
        "       return sent\n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "OmQerhvR5C1E"
      },
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner = TextCleaning(False)"
      ],
      "metadata": {
        "id": "gM8WIwGj5Jfv"
      },
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaner.clean([\"List of text data\"])"
      ],
      "metadata": {
        "id": "HTjIfJaZAFJ7"
      },
      "execution_count": 346,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}